{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XjXLOlJOlxn",
        "outputId": "5ec17927-9bd9-45cb-b24b-337b4be87445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/main_combined_dataset.zip\n",
            "replace /content/main_combined_dataset/main_combined_dataset/images/img_00000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/main_combined_dataset/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5cf3ce3f0b83>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegmentationOrientedDefectDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Subset and split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5cf3ce3f0b83>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, mask_dir, transform)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/main_combined_dataset/images'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torchvision import transforms as TF\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import quickshift\n",
        "from scipy import stats\n",
        "from collections import deque\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy model and dataset from Drive\n",
        "!cp /content/drive/MyDrive/UNet_segmentation.pth /content/UNet_segmentation.pth\n",
        "!unzip /content/drive/MyDrive/main_combined_dataset.zip -d /content/main_combined_dataset\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Dataset class\n",
        "class SegmentationOrientedDefectDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=True):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_names = sorted(os.listdir(image_dir))\n",
        "        self.mask_names = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_names[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_names[idx])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # grayscale (for binary)\n",
        "\n",
        "        if self.transform:\n",
        "            image, mask = self.augment(image, mask)\n",
        "\n",
        "        # Normalize image and convert to tensor\n",
        "        image = TF.to_tensor(image)\n",
        "        image = TF.normalize(image, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "\n",
        "        # Convert mask to tensor and binarize\n",
        "        mask = TF.to_tensor(mask)\n",
        "        mask = (mask > 0.5).float()  # Ensure binary mask (0 or 1)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def augment(self, image, mask):\n",
        "        # Random Horizontal Flip\n",
        "        if random.random() > 0.5:\n",
        "            image = TF.hflip(image)\n",
        "            mask = TF.hflip(mask)\n",
        "\n",
        "        # Random Vertical Flip\n",
        "        if random.random() > 0.5:\n",
        "            image = TF.vflip(image)\n",
        "            mask = TF.vflip(mask)\n",
        "\n",
        "        # Random rotation\n",
        "        angle = random.choice([0, 90, 180, 270])\n",
        "        image = TF.rotate(image, angle)\n",
        "        mask = TF.rotate(mask, angle)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Set dataset paths (from extracted folder)\n",
        "image_dir = \"/content/main_combined_dataset/images\"\n",
        "mask_dir = \"/content/main_combined_dataset/masks\"\n",
        "\n",
        "# Load dataset\n",
        "full_dataset = SegmentationOrientedDefectDataset(image_dir, mask_dir, transform=True)\n",
        "\n",
        "# Subset and split\n",
        "random_indices = random.sample(range(len(full_dataset)), 5000)\n",
        "dataset = Subset(full_dataset, random_indices)\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Visualize dataset\n",
        "def visualize_dataset(data_loader, num_samples=4):\n",
        "    images, masks = next(iter(data_loader))\n",
        "\n",
        "    images = images * 0.5 + 0.5  # Denormalize\n",
        "    images = images.numpy()\n",
        "    masks = masks.numpy()\n",
        "\n",
        "    plt.figure(figsize=(12, 4 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        img = images[i].transpose(1, 2, 0)  # CHW -> HWC\n",
        "        mask = masks[i][0]  # binary mask (1, H, W) -> (H, W)\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2 * i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2 * i + 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(\"Mask\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_dataset(train_loader, num_samples=5)\n",
        "\n",
        "# UNet model definition\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.encoder1 = conv_block(3, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.encoder2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.encoder3 = conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.bottle_neck = conv_block(256, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.decoder3 = conv_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.decoder2 = conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.decoder1 = conv_block(128, 64)\n",
        "        self.output = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(self.pool1(e1))\n",
        "        e3 = self.encoder3(self.pool2(e2))\n",
        "        b = self.bottle_neck(self.pool3(e3))\n",
        "        d3 = self.up3(b)\n",
        "        d3 = self.decoder3(torch.cat([d3, e3], dim=1))\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.decoder2(torch.cat([d2, e2], dim=1))\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.decoder1(torch.cat([d1, e1], dim=1))\n",
        "        out = self.output(d1)\n",
        "        return out\n",
        "\n",
        "# Load pre-trained model\n",
        "model = UNet().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/UNet_segmentation.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Define evaluation metrics\n",
        "def dice_coefficient(preds, targets, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate the Dice coefficient between predicted and target binary masks.\n",
        "\n",
        "    Args:\n",
        "        preds (torch.Tensor): Predicted values (probabilities) from the model, typically after sigmoid.\n",
        "        targets (torch.Tensor): Ground truth binary mask with values 0 or 1.\n",
        "        threshold (float, optional): Threshold for binarizing predictions. Defaults to 0.5.\n",
        "\n",
        "    Returns:\n",
        "        float: Dice coefficient value.\n",
        "    \"\"\"\n",
        "    # Binarize predictions: convert probabilities to 0 or 1 based on threshold\n",
        "    preds = (preds > threshold).float()\n",
        "\n",
        "    # Calculate intersection: sum of element-wise product of preds and targets\n",
        "    intersection = (preds * targets).sum()\n",
        "\n",
        "    # Calculate Dice coefficient: 2 * intersection / (sum of preds + sum of targets)\n",
        "    # Add small epsilon (1e-8) to denominator to avoid division by zero\n",
        "    dice = (2. * intersection) / (preds.sum() + targets.sum() + 1e-8)\n",
        "\n",
        "    return dice\n",
        "\n",
        "def iou_score(preds, targets, threshold=0.5):\n",
        "    preds = (torch.sigmoid(preds) > threshold).float()\n",
        "    intersection = (preds * targets).sum()\n",
        "    union = preds.sum() + targets.sum() - intersection\n",
        "    return intersection / (union + 1e-8)\n",
        "\n",
        "# Visualization function for single prediction\n",
        "def visualize_prediction(image, mask, pred, alpha=0.6):\n",
        "    image_np = (image * 0.5 + 0.5).cpu().permute(1, 2, 0).numpy()  # Denormalize\n",
        "    mask_np = mask.cpu().squeeze().numpy()\n",
        "    pred_np = pred.cpu().squeeze().numpy()\n",
        "\n",
        "    overlay = image_np.copy()\n",
        "    green_mask = np.zeros_like(image_np)\n",
        "    green_mask[..., 1] = 1  # Green channel\n",
        "    overlay_mask = np.where(pred_np[..., None] > 0, green_mask, 0)\n",
        "    overlay = (1 - alpha) * image_np + alpha * overlay_mask\n",
        "    overlay = np.clip(overlay, 0, 1)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    axs[0].imshow(image_np)\n",
        "    axs[0].set_title('Original Image')\n",
        "    axs[1].imshow(mask_np, cmap='gray')\n",
        "    axs[1].set_title('Ground Truth Mask')\n",
        "    axs[2].imshow(pred_np, cmap='gray')\n",
        "    axs[2].set_title('Predicted Mask')\n",
        "    axs[3].imshow(overlay)\n",
        "    axs[3].set_title('Overlay on Image')\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Predict and evaluate without refinement\n",
        "def predict_and_evaluate(model, test_loader, device, save_dir=\"predicted_masks\", threshold=0.5, num_visualize=5):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, masks) in enumerate(test_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds_bin = (preds > threshold).float()\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                pred_mask = preds_bin[i][0].cpu().numpy() * 255\n",
        "                pred_mask_img = Image.fromarray(pred_mask.astype(np.uint8))\n",
        "                pred_mask_img.save(os.path.join(save_dir, f\"pred_{idx * test_loader.batch_size + i}.png\"))\n",
        "\n",
        "                dice = dice_coefficient(preds[i], masks[i])\n",
        "                iou = iou_score(preds[i], masks[i])\n",
        "                dice_scores.append(dice.item())\n",
        "                iou_scores.append(iou.item())\n",
        "\n",
        "                if idx * test_loader.batch_size + i < num_visualize:\n",
        "                    visualize_prediction(images[i], masks[i], preds_bin[i])\n",
        "\n",
        "    print(f\"\\nAverage Dice Score on Test Set: {np.mean(dice_scores):.4f}\")\n",
        "    print(f\"Average IoU Score on Test Set: {np.mean(iou_scores):.4f}\")\n",
        "\n",
        "predict_and_evaluate(model, test_loader, device, save_dir=\"predicted_masks\", threshold=0.5)\n",
        "\n",
        "# Region Growth Refinement\n",
        "def region_growing(image, seed_spacing=10, threshold=0.1):\n",
        "    H, W = image.shape[:2]\n",
        "    label_map = np.zeros((H, W), dtype=int)\n",
        "    label_counter = 1\n",
        "    neighbors = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "\n",
        "    for i in range(0, H, seed_spacing):\n",
        "        for j in range(0, W, seed_spacing):\n",
        "            if label_map[i, j] == 0:\n",
        "                seed_color = image[i, j]\n",
        "                queue = deque([(i, j)])\n",
        "                label_map[i, j] = label_counter\n",
        "\n",
        "                while queue:\n",
        "                    x, y = queue.popleft()\n",
        "                    for dx, dy in neighbors:\n",
        "                        nx, ny = x + dx, y + dy\n",
        "                        if 0 <= nx < H and 0 <= ny < W and label_map[nx, ny] == 0:\n",
        "                            color_diff = np.linalg.norm(image[nx, ny] - seed_color)\n",
        "                            if color_diff < threshold:\n",
        "                                label_map[nx, ny] = label_counter\n",
        "                                queue.append((nx, ny))\n",
        "                label_counter += 1\n",
        "\n",
        "    return label_map\n",
        "\n",
        "def refine_with_region_growth(pred_mask, image, seed_spacing=10, threshold=0.1):\n",
        "    label_map = region_growing(image, seed_spacing, threshold)\n",
        "    refined_mask = np.zeros_like(pred_mask)\n",
        "\n",
        "    for label in np.unique(label_map):\n",
        "        if label == 0:\n",
        "            continue\n",
        "        region_mask = (label_map == label)\n",
        "        majority_vote = stats.mode(pred_mask[region_mask].flatten(), keepdims=False).mode\n",
        "        refined_mask[region_mask] = majority_vote\n",
        "\n",
        "    return refined_mask\n",
        "\n",
        "def evaluation_with_region_growth_refinement(model, test_loader, save_dir, threshold=0.5, num_visualize=5):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, masks) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds_bin = (preds > threshold).float()\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                image = (images[i] * 0.5 + 0.5).cpu().permute(1, 2, 0).numpy()  # Denormalize\n",
        "                pred_mask = preds_bin[i].squeeze().cpu().numpy()\n",
        "\n",
        "                refined_mask = refine_with_region_growth(pred_mask, image, seed_spacing=10, threshold=0.1)\n",
        "\n",
        "                refined_img = Image.fromarray((refined_mask * 255).astype(np.uint8))\n",
        "                refined_img.save(os.path.join(save_dir, f\"region_growth_refined_{idx * test_loader.batch_size + i}.png\"))\n",
        "\n",
        "                if idx * test_loader.batch_size + i < num_visualize:\n",
        "                    visualize_prediction(images[i], masks[i], torch.tensor(refined_mask))\n",
        "\n",
        "save_dir = \"UNet_region_growth_refined\"\n",
        "evaluation_with_region_growth_refinement(model, test_loader, save_dir, threshold=0.5)\n",
        "\n",
        "# Mean Shift Clustering Refinement\n",
        "def mean_shift_clustering(image, kernel_size=3, max_dist=10):\n",
        "    segments = quickshift(image, kernel_size=kernel_size, max_dist=max_dist, convert2lab=False)\n",
        "    return segments\n",
        "\n",
        "def refine_with_mean_shift(pred_mask, image, kernel_size=3, max_dist=10):\n",
        "    segments = mean_shift_clustering(image, kernel_size, max_dist)\n",
        "    refined_mask = np.zeros_like(pred_mask)\n",
        "\n",
        "    for label in np.unique(segments):\n",
        "        region_mask = (segments == label)\n",
        "        majority_vote = stats.mode(pred_mask[region_mask].flatten(), keepdims=False).mode\n",
        "        refined_mask[region_mask] = majority_vote\n",
        "\n",
        "    return refined_mask\n",
        "\n",
        "def evaluation_with_mean_shift_refinement(model, test_loader, save_dir, threshold=0.5, num_visualize=5):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, masks) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds_bin = (preds > threshold).float()\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                image = (images[i] * 0.5 + 0.5).cpu().permute(1, 2, 0).numpy()  # Denormalize\n",
        "                pred_mask = preds_bin[i].squeeze().cpu().numpy()\n",
        "\n",
        "                refined_mask = refine_with_mean_shift(pred_mask, image, kernel_size=3, max_dist=10)\n",
        "\n",
        "                refined_img = Image.fromarray((refined_mask * 255).astype(np.uint8))\n",
        "                refined_img.save(os.path.join(save_dir, f\"mean_shift_refined_{idx * test_loader.batch_size + i}.png\"))\n",
        "\n",
        "                if idx * test_loader.batch_size + i < num_visualize:\n",
        "                    visualize_prediction(images[i], masks[i], torch.tensor(refined_mask))\n",
        "\n",
        "save_dir = \"UNet_mean_shift_refined\"\n",
        "evaluation_with_mean_shift_refinement(model, test_loader, save_dir, threshold=0.5)\n",
        "\n",
        "# Full pipeline visualization\n",
        "def visualize_full_pipeline(image, mask, pred_mask, region_growth_refined, mean_shift_refined):\n",
        "    image_np = (image * 0.5 + 0.5).cpu().permute(1, 2, 0).numpy()  # Denormalize\n",
        "    mask_np = mask.cpu().squeeze().numpy()\n",
        "    pred_mask_np = pred_mask\n",
        "    region_growth_np = region_growth_refined\n",
        "    mean_shift_np = mean_shift_refined\n",
        "\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    axs[0].imshow(image_np)\n",
        "    axs[0].set_title(\"Original Image\")\n",
        "    axs[1].imshow(mask_np, cmap='gray')\n",
        "    axs[1].set_title(\"Ground Truth\")\n",
        "    axs[2].imshow(pred_mask_np, cmap='gray')\n",
        "    axs[2].set_title(\"Predicted Mask\")\n",
        "    axs[3].imshow(region_growth_np, cmap='gray')\n",
        "    axs[3].set_title(\"Region Growth Refined\")\n",
        "    axs[4].imshow(mean_shift_np, cmap='gray')\n",
        "    axs[4].set_title(\"Mean Shift Refined\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize full pipeline for a few test images\n",
        "num_visualize = 5\n",
        "with torch.no_grad():\n",
        "    for idx in range(num_visualize):\n",
        "        image, mask = test_dataset[idx]\n",
        "        image_input = image.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image_input)\n",
        "        pred = torch.sigmoid(output).squeeze().cpu().numpy()\n",
        "        pred_bin = (pred > 0.5).astype(np.uint8)\n",
        "\n",
        "        image_np = (image * 0.5 + 0.5).permute(1, 2, 0).numpy()  # Denormalize\n",
        "\n",
        "        # Apply refinements\n",
        "        region_growth_refined = refine_with_region_growth(pred_bin, image_np)\n",
        "        mean_shift_refined = refine_with_mean_shift(pred_bin, image_np)\n",
        "\n",
        "        visualize_full_pipeline(image, mask, pred_bin, region_growth_refined, mean_shift_refined)"
      ]
    }
  ]
}