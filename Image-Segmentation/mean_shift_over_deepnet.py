# -*- coding: utf-8 -*-
"""Mean_Shift_Over_DeepNet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ubGpyqjohj02aDlGZmxxAOhZ8yB1RMDt
"""

# ============================
# 0. Mount Google Drive and Unzip Dataset
# ============================
from google.colab import drive
drive.mount("/content/drive")  # Follow prompts to authorize

# Unzip the dataset from Drive (adjust the path if needed)
!unzip -q /content/drive/MyDrive/main_combined_dataset.zip -d /content/
print("Dataset unzipped. Check '/content/main_combined_dataset' for images and masks.")

# ============================
# 1. DATASET AND DATALOADER SETUP
# ============================
import os
import random
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset, random_split, DataLoader
import torchvision.transforms.functional as TF
import torch
import numpy as np

class DefectSegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=True):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.image_names = sorted(os.listdir(image_dir))
        self.mask_names = sorted(os.listdir(mask_dir))

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        # Load image and mask
        img_path = os.path.join(self.image_dir, self.image_names[idx])
        mask_path = os.path.join(self.mask_dir, self.mask_names[idx])

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")  # binary mask

        # Apply transformation/augmentation if enabled.
        if self.transform:
            image, mask = self.augment(image, mask)

        # Normalize image and convert to tensor.
        image = TF.to_tensor(image)
        # Assume normalization: (x-0.5)/0.5
        image = TF.normalize(image, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])

        # Convert mask to tensor and binarize.
        mask = TF.to_tensor(mask)
        mask = (mask > 0.5).float()

        return image, mask

    def augment(self, image, mask):
        # Random horizontal flip.
        if random.random() > 0.5:
            image = TF.hflip(image)
            mask = TF.hflip(mask)
        # Random vertical flip.
        if random.random() > 0.5:
            image = TF.vflip(image)
            mask = TF.vflip(mask)
        # Random rotation.
        angle = random.choice([0, 90, 180, 270])
        image = TF.rotate(image, angle)
        mask = TF.rotate(mask, angle)
        return image, mask

# Paths to extracted images and masks.
image_dir = "/content/main_combined_dataset/images"
mask_dir  = "/content/main_combined_dataset/masks"
full_dataset = DefectSegmentationDataset(image_dir, mask_dir, transform=True)

# Split dataset (70% train, 15% val, 15% test).
train_size = int(0.7 * len(full_dataset))
val_size   = int(0.15 * len(full_dataset))
test_size  = len(full_dataset) - train_size - val_size
train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])

# Create DataLoaders.
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False)

# ============================
# 2. DEEPLABv3 MODEL DEFINITION FOR BINARY SEGMENTATION
# ============================
import torch.nn as nn
import torchvision.models as models

def get_deeplabv3(num_classes=1):
    # Load pretrained DeepLabv3 with ResNet50 backbone.
    model = models.segmentation.deeplabv3_resnet50(pretrained=True)
    # Replace the classifier head.
    model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)
    return model

# Initialize the model.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = get_deeplabv3(num_classes=1).to(device)

# ============================
# 3. TRAINING THE MODEL
# ============================
import torch.optim as optim

def dice_coefficient(preds, targets, threshold=0.5):
    preds = (torch.sigmoid(preds) > threshold).float()
    intersection = (preds * targets).sum()
    return (2. * intersection) / (preds.sum() + targets.sum() + 1e-8)

def iou_score(preds, targets, threshold=0.5):
    preds = (torch.sigmoid(preds) > threshold).float()
    intersection = (preds * targets).sum()
    union = preds.sum() + targets.sum() - intersection
    return intersection / (union + 1e-8)

def train_model(model, train_loader, val_loader, device, num_epochs=30, lr=1e-4, checkpoint_path="deeplabv3_best.pth"):
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    best_val_dice = 0.0

    for epoch in range(num_epochs):
        model.train()
        train_loss, train_dice = 0.0, 0.0

        for images, masks in train_loader:
            images, masks = images.to(device), masks.to(device)
            # For DeepLabv3, extract output using ['out']
            outputs = model(images)['out']
            loss = criterion(outputs, masks)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_dice += dice_coefficient(outputs, masks).item()

        train_loss /= len(train_loader)
        train_dice /= len(train_loader)

        # Validation phase.
        model.eval()
        val_loss, val_dice, val_iou = 0.0, 0.0, 0.0
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)['out']
                loss = criterion(outputs, masks)
                val_loss += loss.item()
                val_dice += dice_coefficient(outputs, masks).item()
                val_iou += iou_score(outputs, masks).item()

        val_loss /= len(val_loader)
        val_dice /= len(val_loader)
        val_iou /= len(val_loader)

        print(f"Epoch [{epoch+1}/{num_epochs}]")
        print(f"Train Loss: {train_loss:.4f} | Dice: {train_dice:.4f}")
        print(f"Val Loss: {val_loss:.4f} | Dice: {val_dice:.4f} | IoU: {val_iou:.4f}\n")

        if val_dice > best_val_dice:
            best_val_dice = val_dice
            torch.save(model.state_dict(), checkpoint_path)
            print(f"Saved new best model (Dice: {val_dice:.4f})")

    print("Training complete.")

# Uncomment the following line to train (or use a pre-trained checkpoint).
# train_model(model, train_loader, val_loader, device, num_epochs=30, lr=1e-4)

# Optionally, load the best checkpoint:
# model.load_state_dict(torch.load("deeplabv3_best.pth", map_location=device))

# ============================
# 4. MEAN SHIFT SEGMENTATION FUNCTIONS
# ============================
import cv2
from skimage.measure import label

def generate_mean_shift_segments(image, spatial_radius=21, color_radius=51, quantization_level=16):
    """
    Generate segmentation labels using mean shift filtering.
    - image: NumPy array in RGB float format [0,1].
    Returns an integer label map of segments.
    """
    # Convert image to uint8 [0,255] and then to BGR.
    image_uint8 = (image * 255).astype(np.uint8)
    image_bgr = cv2.cvtColor(image_uint8, cv2.COLOR_RGB2BGR)
    filtered_bgr = cv2.pyrMeanShiftFiltering(image_bgr, spatial_radius, color_radius)
    filtered_rgb = cv2.cvtColor(filtered_bgr, cv2.COLOR_BGR2RGB)
    quantized = (filtered_rgb // quantization_level) * quantization_level
    # Flatten to combine channels; cast to uint32 to avoid overflow.
    flat = quantized.reshape(-1, 3).astype(np.uint32)
    flat_int = flat[:, 0] * 256 * 256 + flat[:, 1] * 256 + flat[:, 2]
    quantized_int = flat_int.reshape(quantized.shape[0], quantized.shape[1])
    segments = label(quantized_int, connectivity=1)
    return segments

def refine_with_mean_shift(pred_mask, segments):
    """
    Refine the predicted binary mask via majority voting within each mean shift segment.
    """
    refined_mask = np.zeros_like(pred_mask)
    unique_segments = np.unique(segments)
    for seg_val in unique_segments:
        region = (segments == seg_val)
        majority_label = np.mean(pred_mask[region]) > 0.5
        refined_mask[region] = majority_label
    return refined_mask

# ============================
# 5. INFERENCE PIPELINE WITH MEAN SHIFT REFINEMENT
# ============================
import matplotlib.pyplot as plt

def visualize_prediction(image, mask, pred):
    """
    Visualize the original image, ground truth mask, and the refined prediction.
    """
    # Denormalize image for display.
    image_np = image.cpu().permute(1,2,0).numpy()
    mask_np = mask.cpu().squeeze().numpy()
    pred_np = pred.cpu().squeeze().numpy()

    fig, axs = plt.subplots(1, 3, figsize=(12,4))
    axs[0].imshow(image_np)
    axs[0].set_title("Original Image")
    axs[1].imshow(mask_np, cmap='gray')
    axs[1].set_title("Ground Truth")
    axs[2].imshow(pred_np, cmap='gray')
    axs[2].set_title("Mean Shift Refined")
    for ax in axs:
        ax.axis("off")
    plt.tight_layout()
    plt.show()

def mean_shift_refinement_pipeline(model, test_loader, save_dir, device, threshold=0.5, num_visualize=5):
    """
    Run DeepLabv3 inference on the test set, apply mean shift segmentation,
    and refine the predicted binary mask via majority voting.
    Save refined masks and visualize some examples.
    """
    os.makedirs(save_dir, exist_ok=True)
    model.eval()
    with torch.no_grad():
        for idx, (images, masks) in enumerate(test_loader):
            images = images.to(device)
            masks = masks.to(device)
            # For DeepLabv3, extract output with ['out']
            outputs = model(images)['out']
            preds = torch.sigmoid(outputs)
            preds_bin = (preds > threshold).float()

            for i in range(images.size(0)):
                image_tensor = images[i]
                gt_mask = masks[i]
                # Get binary prediction.
                pred_mask = preds_bin[i].squeeze().cpu().numpy()

                # Convert image to numpy and unnormalize (assumes normalization: (x-0.5)/0.5).
                image_np = image_tensor.cpu().permute(1,2,0).numpy()
                image_np = image_np * 0.5 + 0.5  # now in [0,1]

                # Compute mean shift segmentation.
                segments = generate_mean_shift_segments(image_np, spatial_radius=21, color_radius=51, quantization_level=16)
                # Refine prediction.
                refined_mask = refine_with_mean_shift(pred_mask, segments)

                # Save refined mask.
                save_path = os.path.join(save_dir, f"mean_shift_refined_{idx * test_loader.batch_size + i}.png")
                Image.fromarray((refined_mask * 255).astype(np.uint8)).save(save_path)

                # Visualize a few examples.
                if idx * test_loader.batch_size + i < num_visualize:
                    visualize_prediction(image_tensor, gt_mask, torch.tensor(refined_mask))
    print("Mean shift segmentation refinement complete.")

# ============================
# 6. MAIN INVOCATION
# ============================
if __name__ == "__main__":
    # Optionally, train the model (or load a pretrained checkpoint).
    # Uncomment to train:
    # train_model(model, train_loader, val_loader, device, num_epochs=30, lr=1e-4, checkpoint_path="deeplabv3_best.pth")

    # Alternatively, load the best checkpoint:
    model.load_state_dict(torch.load("deepnetv3.pth", map_location=device))

    # Run inference with mean shift refinement on test set.
    results_dir = "mean_shift_results"
    mean_shift_refinement_pipeline(model, test_loader, results_dir, device, threshold=0.5, num_visualize=5)